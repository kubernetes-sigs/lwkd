---
layout: post
title: Week Ending December 9, 2018
date: 2018-12-10 22:00:00 -0000
slug: 2018-12-09-update
---

## Community Meeting Summary

Rather than the normal community meeting, this week we had the [1.13 release retrospective](http://bit.ly/k8s113-retro). I highly recommended checking out the full transcript, but some general themes:

* Pre-announcing and repeating the "stability" theme went well.
* Good collaboration between leads and shadows on the release team.
* Some useful experiments with issue tracking, but needs more work.
* Release was on time! Yay!
* Glog -> Klog was poorly communicated and caused a lot of confusion.
* Several release phases coincided with holidays or conferences, which lead to SIG availability issues.
* CI signal is improving, but a lot of non-blockers tests are still very flakey.

## Release Schedule

We're still in the inter-release period between 1.13 and 1.14, a bit more extended that usual due to Kubecon NA. Most of the [1.14 release leads](https://github.com/kubernetes/sig-release/blob/master/releases/release-1.14/release_team.md) have been volunteered but the team is still looking for shadows. If you've never helped with a release before and are interested in helping out, please contact SIG-Release!

Additionally the 1.13.1 release is currently in beta, with a [1.13.1-beta.0 tag](https://github.com/kubernetes/kubernetes/compare/v1.13.0...v1.13.1-beta.0) up, with a full release planned for December 13th.

We would like to again highlight [CVE-2018-1002105](https://nvd.nist.gov/vuln/detail/CVE-2018-1002105) and remind everyone to patch their clusters if they have not already.

## Featured PRs

It's been a light week again as 1.14 is still in early days and many people were in transit for Kubecon NA, but we did have some work land:

### [#57057: Reschedule with backoff](https://github.com/kubernetes/kubernetes/pull/57057)

A further update to the new scheduling queue system on top of last week's queue sorting, this PR adds a backoff timer before attempting to schedule the pod again. This can further improve things in a resource-constrained situation as the scheduler won't be stuck in a busy loop forever. This is yet more improved by [PR #71551](https://github.com/kubernetes/kubernetes/pull/71551) which avoids re-activating the scheduler if nothing on the nodes has changed. Overall these changes together should substantially improve the behavior of the scheduler when in a long-term starvation.

### [#71792: Ensure all new API versions of resources default to DeleteDependents](https://github.com/kubernetes/kubernetes/pull/71792)

Future proofing! This PR ensures that we won't forget to change the default cascade behavior for future object versions to `DeleteDependents`. Specifically it codes in the current (as of today) version of each object and ensures that all future versions will automatically switch behavior. This shouldn't affect anything now, but it does ensure we won't miss this important change in a later release.

### [#68663: Disable proxy use in http probe](https://github.com/kubernetes/kubernetes/pull/68663)

A small change, but possibly an issue in funky development setups. This PR makes sure that if the kubelet is started with an `HTTP_PROXY` environment variable (or similar), it won't get used during liveness/readiness probes. If you were (ab)using this feature, you will need to switch to a command probe and implement the HTTP proxy usage yourself in that script.

## Version Updates

* [etcd to 3.3.10](https://github.com/kubernetes/kubernetes/pull/71615)
* [node-problem-detector to 0.6.0 (for GCI)](https://github.com/kubernetes/kubernetes/pull/71522)
